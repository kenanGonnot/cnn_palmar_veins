{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201f849e-4ab4-4b50-a94d-cfb8936ecb73",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Palm vein recognition\n",
    "\n",
    "\n",
    "Ici, vous allez trouver tous les étapes nécessaires pour développer un modèle de CNN pour la reconnaissance de veines palmaires. \n",
    "\n",
    "Ce projet a été développé par : Kenan GONNOT, Lorenzo MARQUES et Fayçal MERZOUK.  \n",
    "\n",
    "**L’objectif** est de créer un modèle de veines verification : «Est-ce la bonne personne ? »\n",
    "\n",
    "Vous pouvez retrouver ce code sur [GitHub](https://github.com/kenanGonnot/cnn_palmar_veins). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eca71d-8844-4d21-a4f6-aafaa3c6744e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Imports](#1)\n",
    "- [2 - Load images](#2)\n",
    "    - [2.1 - Preprocess datasets](#3)\n",
    "    - [2.2 - Plot image](#4)\n",
    "- [3 - Split dataset - Train(70%) Test(15%) Val(15%)](#5)\n",
    "- [4 - Create model CNN](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0c773-557b-4e0f-b85c-a28b429c62fb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b097322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f6592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.random.set_seed(0)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f659ca0-bb6b-4c1f-a2d9-da894d0520de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc04ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/data_palm_vein/NIR\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecf22885-a37b-4da7-bbe8-bbb59d9c6e8d",
   "metadata": {},
   "source": [
    "def load_img1(path, xdim=128, ydim=128, nmax = 6000):\n",
    "    label_names = []\n",
    "    X = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    #print(\"Loading images...\")\n",
    "    for dirname in tqdm_notebook(os.listdir(path), desc=\"Loading images...\"):\n",
    "        #print(\"dirname : \", dirname)\n",
    "        label_names.append(dirname)\n",
    "        data_path = os.path.join(path + \"/\" + dirname, '*g')\n",
    "        # print(\"data_path: \" + data_path)\n",
    "        files = glob.glob(data_path)\n",
    "        #print(\"Count = \", count)\n",
    "        if count > nmax: break\n",
    "        for f1 in files:\n",
    "            #print(\"files : \", f1)\n",
    "            #img = cv2.imread(f1)\n",
    "            #img = cv2.imread(f1, cv2.IMREAD_GRAYSCALE)\n",
    "            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.imread(f1, 0)\n",
    "            #img = cv2.resize(img, (xdim, ydim))\n",
    "            X.append(np.array(img))\n",
    "            y.append(dirname)\n",
    "            count += 1\n",
    "    print(count, ' images lues')\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"\\ny.shape = \", y.shape)\n",
    "    print(\"X.shape = \", X.shape)\n",
    "    gc.collect()\n",
    "    return X, y, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a38c05-b16f-461c-9e0d-57e0652b9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, xdim=128, ydim=128, nmax = 6000):\n",
    "    label_names = []\n",
    "    X = []\n",
    "    y = []\n",
    "    nmax = nmax - 1\n",
    "    count = 0\n",
    "    identity = -1\n",
    "    #print(\"Loading images...\")\n",
    "    for dirname in tqdm_notebook(os.listdir(path), desc=\"Loading images...\"):\n",
    "        if dirname == \".DS_Store\": continue\n",
    "        #print(\"dirname : \", dirname)\n",
    "        label_names.append(dirname)\n",
    "        data_path = os.path.join(path + \"/\" + dirname, '*g')\n",
    "        # print(\"data_path: \" + data_path)\n",
    "        files = glob.glob(data_path)\n",
    "        identity += 1\n",
    "        #print(\"Count = \", count)\n",
    "        if count > nmax: break\n",
    "        for f1 in files:\n",
    "            #print(\"files : \", f1)\n",
    "            #img = cv2.imread(f1)\n",
    "            img = cv2.imread(f1, cv2.IMREAD_GRAYSCALE)\n",
    "            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #img = cv2.imread(f1, 0)\n",
    "            #img = cv2.resize(img, (xdim, ydim))\n",
    "            X.append(np.array(img))\n",
    "            y.append(identity)\n",
    "            count += 1\n",
    "    print(count, ' images lues')\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"\\ny.shape = \", y.shape)\n",
    "    print(\"X.shape = \", X.shape)\n",
    "    gc.collect()\n",
    "    return X, y, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931f9228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e8dc18705341e3ab4ad75aef68979d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images...:   0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600  images lues\n",
      "\n",
      "y.shape =  (600,)\n",
      "X.shape =  (600, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "X, y, label_names = load_img(path_data, nmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a78d3-271c-484a-b2bd-4cd879e17934",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5c34336-c475-407d-84f6-886458a7bd98",
   "metadata": {},
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a717f-ca4b-4a6b-8f0f-fd8956374746",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185379c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"\\nPREPROCESSING DATA\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"\\nX shape : {}\".format(X.shape))\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"y shape : {}\\n\".format(y.shape))\n",
    "print(\"\\n\\n-----------------------------------------\")\n",
    "print(\"Il y a {} utilisateur(s) dans le dataset prélevé.\".format(y.shape[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "186f966e-968f-41c9-9274-e8e3037b4594",
   "metadata": {},
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae66197-2307-440a-95f7-14ec65dead82",
   "metadata": {},
   "source": [
    "## Plot image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = randrange(y.shape[1])\n",
    "print(j)\n",
    "plt.imshow(X[j], cmap='gray')\n",
    "#plt.imshow(X[j])\n",
    "plt.show()\n",
    "#print(\"\\ny : \\n\",y[j])\n",
    "#print(X[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc535d9c-bd9a-4109-ac8a-6dbdd02cb6ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split dataset - Train(70%) Test(15%) Val(15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df6aa1-ffa7-481a-bda7-8b2ea39380d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomstate : 46\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"\\nSplitting data ...\\n\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"\\nX_train shape : {}    |   y_train shape : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"\\n(X_temp shape : {}    |   y_temp shape : {})\".format(X_temp.shape, y_temp.shape))\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"\\nX_test shape  : {}    |   y_test shape  : {}\".format(X_test.shape, y_test.shape))\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"\\nX_val shape   : {}    |   y_val shape   : {}\".format(X_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d70281-234a-4cb0-9a6e-b44a94c29903",
   "metadata": {},
   "source": [
    "## Zfnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50747e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zfnet_model(input_shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=96, kernel_size=(7, 7), strides=(2, 2), padding=\"valid\", activation=\"relu\",\n",
    "                     kernel_initializer=\"uniform\", input_shape=input_shape))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # model.add(Lambda(lambda x: tf.image.per_image_standardization(x)))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding=\"same\",\n",
    "                     activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    # model.add(Lambda(lambda x: tf.image.per_image_standardization(x)))\n",
    "\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                     kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                     kernel_initializer=\"uniform\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding=\"same\",\n",
    "                     activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=4096, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=classes, activation=\"softmax\"))\n",
    "\n",
    "    print(model.summary())\n",
    "    print(\"\\n ================= ZFNET model ================= \\n\")\n",
    "    \n",
    "    #optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    #optimizer = Nadam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    #model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    #learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "    #                                        patience=3, \n",
    "    #                                        verbose=1, \n",
    "    #                                        factor=0.7, \n",
    "    #                                        min_lr=0.00000000001)\n",
    "\n",
    "    \n",
    "    # model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy',\n",
    "    #               metrics=['accuracy', TopKCategoricalAccuracy(1)])\n",
    "    #model.compile(optimizer=Nadam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    #reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=0.00001)\n",
    "    # reduce_lr=0\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2ee76-bd0c-4300-b5ba-612c805cc39b",
   "metadata": {},
   "source": [
    "## Param training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb620244",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nombre_classes = y.shape[1]\n",
    "input_shape = (X.shape[1], X.shape[2], 1)\n",
    "print(\"\\nNombres de classes : {}   |   Input shape : {}\\n\".format(Nombre_classes, input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb920a-3fa2-4f72-b265-722b6106039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zfnet = zfnet_model(input_shape, Nombre_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cd582-4165-43d2-844b-7705a3460468",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 50\n",
    "print(\"\\n ================= Training : ZFNET model ================= \\n\")\n",
    "print(\"  Epochs :  {}   |   Batch size : {} \\n\".format(epochs, batch_size))\n",
    "print(\"\\n ========================================================== \\n\")\n",
    "\n",
    "trained_model = model_zfnet.fit(X_train, y_train, validation_data=(X_temp, y_temp), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09355deb-22a1-416d-8b7d-30e24af65692",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model_zfnet.evaluate(X_temp, y_temp, verbose=0)\n",
    "\n",
    "print(\"\\n ================= Evaluation : ZFNET model ================= \\n\")\n",
    "print(\"  With : \\n\")\n",
    "print(\"Batch size         :  {}    |   Epochs      : {} \".format(batch_size, epochs))\n",
    "print(\"Nombres de classes :  {}    |   Input shape : {} \\n\".format(Nombre_classes, input_shape))\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"  Results : \\n\")\n",
    "print(\"Loss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "128a6f3a-577a-4f66-80ba-8b0c367c8374",
   "metadata": {},
   "source": [
    "epoch = 80\n",
    "batch_size = 50\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.05, # Randomly zoom image \n",
    "        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(X_train)\n",
    "\n",
    "history = model_zfnet.fit_generator(\n",
    "                              datagen.flow(X_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epoch, \n",
    "                              validation_data = (X_temp,y_temp),\n",
    "                              steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                              callbacks=[learning_rate_reduction]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be28a1cc-8d7a-447b-a0a2-417cf2899342",
   "metadata": {},
   "source": [
    "y_pred = model_zfnet.predict(X_temp)\n",
    "\n",
    "y_temp = y_temp.reshape(-1,)\n",
    "\n",
    "diff = y_temp - y_pred\n",
    "diff = diff.reshape(-1,1)\n",
    "\n",
    "true = 0\n",
    "for i in range(0,len(diff)):\n",
    "    if diff[i] == 0:\n",
    "        true = true + 1\n",
    "\n",
    "Cnn_accuracy = round(100*true/len(diff),2)\n",
    "\n",
    "print(\"Cnn_accuracy is %\", Cnn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fba9ea-f907-477f-ac2d-6bd2aab195b2",
   "metadata": {},
   "source": [
    "#### plot score - zfnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ed9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(train):\n",
    "    accuracy = train.history['accuracy']\n",
    "    val_accuracy = train.history['val_accuracy']\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(trained_model)\n",
    "predict_x = model.predict(X_test)\n",
    "y_cnn = np.argmax(predict_x, axis=1)\n",
    "plt.figure(figsize=(15, 25))\n",
    "n_test = X_test.shape[0]\n",
    "i = 1\n",
    "for j in range(len(X_test)):\n",
    "    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i < 10):\n",
    "        plt.subplot(10, 5, i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_test[j])\n",
    "        plt.title('%s / %s' % (Classes[y_cnn[j]], Classes[y_test[j].argmax(axis=-1)]))\n",
    "        i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c73b51-2fae-4b3c-b642-612474a0cfb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "def vgg_model_tf(input_shape=(128, 128, 1), nombre_classes=501):\n",
    "    vgg16 = VGG16(weights=None, include_top=False, input_shape=input_shape)\n",
    "    vgg16.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(vgg16)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e441e-1ad8-44f2-b126-32b29d8b487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = vgg_model_tf(nombre_classes=y.shape[1])\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a560c-6491-4632-84b5-e6c6cfdecc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_vgg = model_vgg.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nLoss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb016e5-774e-4b1f-9398-63e3a4b1918a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Resnet 152 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "def resnet_model_tf(input_shape=(128, 128, 1), nombre_classes=11):\n",
    "    resnet = ResNet152V2(weights=None, include_top=False, input_shape=input_shape)\n",
    "    resnet.tbatch_sizenable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5bd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = resnet_model_tf(nombre_classes=y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df88c0-09e8-43f2-9d34-b9c0014dc1f3",
   "metadata": {},
   "source": [
    "model_resnet.load_weights('saved_model/resnet150_388_51.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ccf50-7ef0-43a1-92c0-305f3005dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_resnet = model_resnet.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a853a4e-64c3-45f5-8279-d14a3d1d82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val = model_resnet.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\nLoss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae7e20-07f4-495e-bfa7-f47fd91f0c94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e8ca6-6c57-48f7-9817-7d40496353c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model_resnet50.save('saved_model/resnet150_388_51.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d0ca3-ec0f-4a96-af9e-506b6211a96f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Resnet 50 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fa1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet import ResNet50\n",
    "\n",
    "def resnet50_model_tf(input_shape=(128, 128, 1), nombre_classes=500):\n",
    "    resnet = ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
    "    resnet.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b16e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50 = resnet50_model_tf()\n",
    "\n",
    "trained_model_resnet50 = model_resnet50.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b35904-2c68-4c44-b7da-9ca7569266e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model_resnet50.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nLoss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model_resnet50.save('saved_model/resnet50_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c6666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "091d4c51-3ee7-4db8-bb99-5d5ff46b7b9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(128, 128, 1)))\n",
    "model.add(Dense(1024, input_dim=(16384,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(501))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ceee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
