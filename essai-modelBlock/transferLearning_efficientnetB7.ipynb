{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed86aefc-f6d0-455d-9aef-bc0b5681cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a213c9-c03b-4f1b-a3a0-6e5333383da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba48d5e6-43f0-4a79-bdf1-366aac61855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/NIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce62474-4908-4ad6-8814-4b41795aa7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 4200 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=64,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fbd595-42be-40bb-859c-9090d02a838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 900 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=64,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0790bf7-e934-411a-a916-cc9be1801f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 900 files for validation.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=64,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9402b5c-c092-4e97-9e4b-8fdc1510d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "def resnet_model_tf(input_shape=(128, 128, 3), nombre_classes=500):\n",
    "    resnet = EfficientNetB0(weights=None, include_top=False, input_shape=input_shape)\n",
    "    resnet.tbatch_sizenable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "#    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "#    model.add(Dropout(0.5))\n",
    "#    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "#    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.7, \n",
    "                                            min_lr=0.00000000001)\n",
    "    return model, learning_rate_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33afcb1f-8954-4f2c-82fc-c45854989d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 4, 4, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20480)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               10240500  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,290,071\n",
      "Trainable params: 14,248,048\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model, learning_rate_reduction = resnet_model_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c38539-3f7c-40d1-a98c-00401c8b6d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================= Training : RESNET model ================= \n",
      "\n",
      "             Epochs :  100   |   Batch size : 64 \n",
      "\n",
      " =========================================================== \n",
      "\n",
      "Epoch 1/100\n",
      "66/66 [==============================] - 24s 258ms/step - loss: 7.4020 - accuracy: 0.0093 - val_loss: 6.4680 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 4.1897 - accuracy: 0.2569 - val_loss: 6.5366 - val_accuracy: 0.0033 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.8556 - accuracy: 0.8079 - val_loss: 7.0815 - val_accuracy: 0.0044 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.2874 - accuracy: 0.9348 - val_loss: 8.6268 - val_accuracy: 0.0067 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.2158 - accuracy: 0.9514 - val_loss: 11.1180 - val_accuracy: 0.0022 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.2457 - accuracy: 0.9483 - val_loss: 8.4747 - val_accuracy: 0.0211 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.2033 - accuracy: 0.9595 - val_loss: 7.2210 - val_accuracy: 0.0111 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.2244 - accuracy: 0.9471 - val_loss: 9.4994 - val_accuracy: 0.0422 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.1411 - accuracy: 0.9676 - val_loss: 6.5357 - val_accuracy: 0.1344 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.1714 - accuracy: 0.9669 - val_loss: 3736.5264 - val_accuracy: 0.0022 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9657\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.1756 - accuracy: 0.9657 - val_loss: 248.6972 - val_accuracy: 0.0067 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0834 - accuracy: 0.9843 - val_loss: 17.3421 - val_accuracy: 0.0567 - lr: 7.0000e-04\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0460 - accuracy: 0.9893 - val_loss: 7.9667 - val_accuracy: 0.3911 - lr: 7.0000e-04\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0532 - accuracy: 0.9900 - val_loss: 1.4776 - val_accuracy: 0.8067 - lr: 7.0000e-04\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 15s 233ms/step - loss: 0.0362 - accuracy: 0.9919 - val_loss: 0.0930 - val_accuracy: 0.9767 - lr: 7.0000e-04\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0330 - accuracy: 0.9926 - val_loss: 0.1962 - val_accuracy: 0.9622 - lr: 7.0000e-04\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9888\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0409 - accuracy: 0.9888 - val_loss: 0.0847 - val_accuracy: 0.9722 - lr: 7.0000e-04\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0256 - accuracy: 0.9940 - val_loss: 0.0590 - val_accuracy: 0.9800 - lr: 4.9000e-04\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 15s 233ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.0547 - val_accuracy: 0.9833 - lr: 4.9000e-04\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 0.0462 - val_accuracy: 0.9867 - lr: 4.9000e-04\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0249 - val_accuracy: 0.9933 - lr: 4.9000e-04\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0188 - accuracy: 0.9960 - val_loss: 0.1095 - val_accuracy: 0.9722 - lr: 4.9000e-04\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9940\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0283 - accuracy: 0.9940 - val_loss: 0.0244 - val_accuracy: 0.9933 - lr: 4.9000e-04\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.0514 - val_accuracy: 0.9878 - lr: 3.4300e-04\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9964\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.1092 - val_accuracy: 0.9800 - lr: 3.4300e-04\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.0753 - val_accuracy: 0.9867 - lr: 2.4010e-04\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9962\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 0.9983 - val_accuracy: 0.8711 - lr: 2.4010e-04\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.3507 - val_accuracy: 0.9489 - lr: 1.6807e-04\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9981\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.0641 - val_accuracy: 0.9822 - lr: 1.6807e-04\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.0366 - val_accuracy: 0.9944 - lr: 1.1765e-04\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0411 - val_accuracy: 0.9944 - lr: 1.1765e-04\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0251 - val_accuracy: 0.9956 - lr: 1.1765e-04\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0311 - val_accuracy: 0.9956 - lr: 1.1765e-04\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9979\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0457 - val_accuracy: 0.9933 - lr: 1.1765e-04\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 15s 233ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0407 - val_accuracy: 0.9911 - lr: 8.2354e-05\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0267 - val_accuracy: 0.9956 - lr: 8.2354e-05\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0352 - val_accuracy: 0.9944 - lr: 5.7648e-05\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.0353603617404586e-05.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0221 - val_accuracy: 0.9944 - lr: 5.7648e-05\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0184 - val_accuracy: 0.9944 - lr: 4.0354e-05\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0177 - val_accuracy: 0.9967 - lr: 4.0354e-05\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 15s 232ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0146 - val_accuracy: 0.9956 - lr: 4.0354e-05\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9990\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.8247522277524694e-05.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.0141 - val_accuracy: 0.9956 - lr: 4.0354e-05\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0144 - val_accuracy: 0.9956 - lr: 2.8248e-05\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.977326610358432e-05.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0125 - val_accuracy: 0.9967 - lr: 2.8248e-05\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.0143 - val_accuracy: 0.9956 - lr: 1.9773e-05\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.3841286272509023e-05.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0148 - val_accuracy: 0.9956 - lr: 1.9773e-05\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0149 - val_accuracy: 0.9967 - lr: 1.3841e-05\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.688900263427058e-06.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0142 - val_accuracy: 0.9967 - lr: 1.3841e-05\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0138 - val_accuracy: 0.9967 - lr: 9.6889e-06\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.782229866075795e-06.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0137 - val_accuracy: 0.9967 - lr: 9.6889e-06\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0161 - val_accuracy: 0.9956 - lr: 6.7822e-06\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.747560842588427e-06.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.0140 - val_accuracy: 0.9967 - lr: 6.7822e-06\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0144 - val_accuracy: 0.9956 - lr: 4.7476e-06\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9990\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 3.3232926853088427e-06.\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.0143 - val_accuracy: 0.9956 - lr: 4.7476e-06\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0197 - val_accuracy: 0.9956 - lr: 3.3233e-06\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 2.3263049115485044e-06.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0235 - val_accuracy: 0.9956 - lr: 3.3233e-06\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0143 - val_accuracy: 0.9967 - lr: 2.3263e-06\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.6284134062516385e-06.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0146 - val_accuracy: 0.9967 - lr: 2.3263e-06\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.0141 - val_accuracy: 0.9967 - lr: 1.6284e-06\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.1398894002923043e-06.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0137 - val_accuracy: 0.9967 - lr: 1.6284e-06\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.0143 - val_accuracy: 0.9967 - lr: 1.1399e-06\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9981\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 7.979225642884557e-07.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.0139 - val_accuracy: 0.9967 - lr: 1.1399e-06\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.0132 - val_accuracy: 0.9967 - lr: 7.9792e-07\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 5.585457870438403e-07.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 7.9792e-07\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0135 - val_accuracy: 0.9967 - lr: 5.5855e-07\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.9098203501453095e-07.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 5.5855e-07\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 3.9098e-07\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 2.73687416552093e-07.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0138 - val_accuracy: 0.9967 - lr: 3.9098e-07\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 2.7369e-07\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9988\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.915811935759848e-07.\n",
      "66/66 [==============================] - 16s 236ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0135 - val_accuracy: 0.9967 - lr: 2.7369e-07\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0190 - val_accuracy: 0.9956 - lr: 1.9158e-07\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.3410683550318935e-07.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0143 - val_accuracy: 0.9956 - lr: 1.9158e-07\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0177 - val_accuracy: 0.9956 - lr: 1.3411e-07\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 9.387478883127187e-08.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0158 - val_accuracy: 0.9956 - lr: 1.3411e-07\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 16s 236ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0229 - val_accuracy: 0.9956 - lr: 9.3875e-08\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9988\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.57123521818903e-08.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0211 - val_accuracy: 0.9956 - lr: 9.3875e-08\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 6.5712e-08\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 4.599864453780355e-08.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0132 - val_accuracy: 0.9967 - lr: 6.5712e-08\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0135 - val_accuracy: 0.9967 - lr: 4.5999e-08\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.2199050181702654e-08.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0149 - val_accuracy: 0.9956 - lr: 4.5999e-08\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0200 - val_accuracy: 0.9956 - lr: 3.2199e-08\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 2.2539335375881817e-08.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0133 - val_accuracy: 0.9967 - lr: 3.2199e-08\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.0128 - val_accuracy: 0.9967 - lr: 2.2539e-08\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9988\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.577753501180723e-08.\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0140 - val_accuracy: 0.9956 - lr: 2.2539e-08\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0136 - val_accuracy: 0.9967 - lr: 1.5778e-08\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9993\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.1044275005644976e-08.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0132 - val_accuracy: 0.9967 - lr: 1.5778e-08\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 16s 234ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0146 - val_accuracy: 0.9956 - lr: 1.1044e-08\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9986\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 7.730992379606505e-09.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0152 - val_accuracy: 0.9956 - lr: 1.1044e-08\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0143 - val_accuracy: 0.9956 - lr: 7.7310e-09\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 5.411694914414511e-09.\n",
      "66/66 [==============================] - 16s 238ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0173 - val_accuracy: 0.9956 - lr: 7.7310e-09\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0125 - val_accuracy: 0.9967 - lr: 5.4117e-09\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 3.788186564435136e-09.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0134 - val_accuracy: 0.9967 - lr: 5.4117e-09\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 16s 236ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0134 - val_accuracy: 0.9967 - lr: 3.7882e-09\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 2.6517306572770847e-09.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0133 - val_accuracy: 0.9967 - lr: 3.7882e-09\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0141 - val_accuracy: 0.9967 - lr: 2.6517e-09\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.8562114290077147e-09.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0130 - val_accuracy: 0.9967 - lr: 2.6517e-09\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 15s 234ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0129 - val_accuracy: 0.9967 - lr: 1.8562e-09\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.2993479847622779e-09.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0128 - val_accuracy: 0.9967 - lr: 1.8562e-09\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0132 - val_accuracy: 0.9967 - lr: 1.2993e-09\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 9.095435737904722e-10.\n",
      "66/66 [==============================] - 16s 235ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0124 - val_accuracy: 0.9967 - lr: 1.2993e-09\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch = 64\n",
    "\n",
    "print(\"\\n ================= Training : RESNET model ================= \\n\")\n",
    "print(\"             Epochs :  {}   |   Batch size : {} \".format(epochs, batch))\n",
    "print(\"\\n =========================================================== \\n\")\n",
    "trained = model.fit(train_ds, validation_data = val_ds, epochs=epochs, batch_size=batch, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2908ddf-2556-4a4e-8dbf-ec5814608aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 52ms/step - loss: 0.0124 - accuracy: 0.9967\n",
      "\n",
      " ================= Evaluation : Resnet model ================= \n",
      "\n",
      "  With : \n",
      "\n",
      "Batch size         :  64     |   Epochs      : 100 \n",
      "Nombres de classes :  500    |   Input shape : (128, 128, 3) \n",
      "\n",
      "\n",
      " ============================================================= \n",
      "\n",
      "  Results : \n",
      "\n",
      "Loss  : 1.24%\n",
      "Score : 99.67%\n"
     ]
    }
   ],
   "source": [
    "val = model.evaluate(test_ds)\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "print(\"\\n ================= Evaluation : Resnet model ================= \\n\")\n",
    "print(\"  With : \\n\")\n",
    "print(\"Batch size         :  {}     |   Epochs      : {} \".format(batch, epochs))\n",
    "print(\"Nombres de classes :  {}    |   Input shape : {} \\n\".format(len(train_ds.class_names), input_shape))\n",
    "print(\"\\n ============================================================= \\n\")\n",
    "\n",
    "print(\"  Results : \\n\")\n",
    "print(\"Loss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0d18fcc-aaae-409f-84d4-ba39d95ac4c8",
   "metadata": {},
   "source": [
    "!mkdir -p saved_model\n",
    "# Saving the model for Future Inferences\n",
    "model_json = cnn.to_json()\n",
    "with open(\"saved_model/efficientnetb0_withoutTL.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "cnn.save('saved_model/efficientnetb0_withoutTL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da67ed0-c8fe-46ff-8f85-f7f6c928399e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77acffe-b5f6-45a7-ae31-4c51c2fafb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAt2ElEQVR4nO3deXxU5fn38c+VSULCngBSJUAAEQVZlIgLYtFqC0VFWy2gUvmppQWxuNSWp+2vLj/tYy0vFyzaYheXHypo0fIg1BUBRZGAYFlckDUIGEICJJCQ5Xr+uGeSCWQDJpwzJ9f79ZrXZOacOXOfOck319znnPuIqmKMMSb+JXjdAGOMMbFhgW6MMQFhgW6MMQFhgW6MMQFhgW6MMQFhgW6MMQFhgW6MMQFhgW4CQ0QuFJGlIrJXRPaIyAcico7X7TLmREn0ugHGxIKItAbmAROA2UAyMAQoieF7hFS1PFbLMybWrEI3QXEagKq+qKrlqnpQVd9U1U8BROQnIrJeRPaLyDoROTv8/Bki8p6IFIjIWhG5MrJAEXlGRJ4SkfkiUgRcLCKniMg/RSRXRDaJyM+j5h8kItkisk9EdonIIyf4MzBNnAW6CYovgHIReVZEhotIWmSCiFwL3Av8GGgNXAnkiUgS8P+AN4GTgNuAmSLSK2q51wEPAq2ApeH5VwOdgO8At4vI98LzPg48rqqtgR64bwrGnDAW6CYQVHUfcCGgwNNArojMFZGOwC3Aw6q6XJ0NqroFOA9oCTykqodU9V1ct82YqEX/S1U/UNUKoC/QQVXvD8+/Mfxeo8PzlgKnikh7VS1U1Y9OxLobE2GBbgJDVder6jhVzQDOBE4BHgM6A1/V8JJTgG3hsI7Ygqu+I7ZF/dwVOCXcPVMgIgXAr4GO4ek347p+PhOR5SJyeQxWy5gGs52iJpBU9TMReQb4KS6Ue9Qw29dAZxFJiAr1Lrjum8pFRf28Ddikqj1rec8vgTEikgD8AHhFRNqpatHxrY0xDWMVugkEETldRO4SkYzw4864rpOPgL8CvxCRgeKcKiJdgWXAAeCXIpIkIkOBK4CXanmbj4H9IvIrEUkVkZCInBk5NFJEbhCRDuF/DgXh11TUsixjYs4C3QTFfuBcYFn4iJSPgDXAXar6Mm7H5gvh+V4D0lX1EC7AhwO7gSeBH6vqZzW9QfiQxcuBAcCm8Gv+CrQJzzIMWCsihbgdpKNV9WDM19SYWohd4MIYY4LBKnRjjAkIC3RjjAkIC3RjjAkIC3RjjAkIz45Db9++vWZmZnr19sYYE5dWrFixW1U71DTNs0DPzMwkOzvbq7c3xpi4JCJbaptmXS7GGBMQFujGGBMQFujGGBMQFujGGBMQFujGGBMQ9Qa6iPxdRL4RkTW1TBcRmSYiG0Tk08ilvYwxxpxYDanQn8GNIleb4UDP8G088NTxN8sYY8zRqvc4dFVdLCKZdcwyEnhO3bCNH4lIWxE5WVV3xKqRTUlZGYRCIBK7ZVZUuFti1NZWhW++cbfo+UpKoLjY3UeIQKtW0KYNtGwJu3fD9u2wcye0aAHf+hZ07AgpKVXLLihw03fudK9v0wbatnU/FxZCURGUlkJSkmtX9C0hoWr9y8tde4qL3WfTooVrQ7NmsG8f7N3r7qMHDQ2FqpbbrFnV7cAB1669e6s+j8RE99qyMncTcc+FQtXbEXk+Kan682Vlbn0KC91nFnmv5GTX9rIy917NmrnPJ/rWrFlVO0Mh93lE1jU52a1ny5bu/SLtKypy61BQ4OaPrIOIe1xW5uaPfE6hkFvfvXvh4MGqdjRrVv3zjmz3yOdcVuban5rqtn2LFtU/p+hbYmLVOiUnVy23tLTqs4lerkjV/ElJ1T/jmj6jxES37SK/N5F2lpQcud0j2yg5uer1hw5VtaO8/Mi/D1W3jSLbK7od0Z+TSNU6VFRUX4eSkqrPMPrzi7QjOdlNi7TjsstgwICj/UuuXyxOLOpE9ct05YSfOyLQRWQ8roqnS5cuMXjr+FBe7n4RKypcqEXLzYXXX4cPP4Rly2DNGvdH1KkTnHyy+yXJy4NW33zF7madSE1LoW1bF6Jdu8IZ6bsoK4P1ezqyZYubN/KLVVhYPfDatIF27dwv57Zt7g+8Jq3Zy1ieJ4ViAEKU05YC2pFHGvkkhK/Z0AZhO534gFP5kp58SU+20JVyEmnJfi7hXb7Lm7RmH1tpxyrSOUDzGt8zjXxOZQM9+ZI08sknjT2kc4DWKEISkIS7WsQ+IJEy0sgnkz20Yj/7aM0e0imgLWXhX+sEKmjDXtLZQxr5JFJW77Y6SCp5tGMP6QCks4d09hCiPPxTOoW0RKn6j9u6huVE2teOPNqwF8G/w1RXkEABbcmjHQW0pZxQjfMJkBy+1TxdSaWw8jNrRkmN85XQrMbPMplDla9tzb5q7csnjUO0o4RWdApv07YUVP4uKlL5O+DmTaYcd/USgJTwLbqtLSiqfL/I7/qJ8tmP/y88++OYL7dB46GHK/R5qnpmDdPm4S6y+3748TvAr1S1ztNAs7KyNAhnipaVwZIlsGJFVQWRlwdbtrjb119XD86ePeGii+CMM+CNN+Ddd13gt20LgwbB2We7+bdvh13by/jO/tf40a5pnJG7hNVdruDBQf+iYK/w9ddwYNMulh7oTwdyeS/xUhaefD2ruv8AadWSlBRo3twtt21bV73k5bnq+tAh6NIFMjPdP4aEcMebCLTfuYas319N8+0bqq1nRWISJS3SKU5NIyE50VWWUk7o622EDhRWzRdKpCi9Cy3yt5FQVkpFi5aUp3cgIT+PUOE+aqOhECWndONgRk9KW7cjcX8Bifv3kFi0DwlXxCJV3zYqJIS2TUPapRNq05KEov0kFOxBCvKhogJV90de3qINh1qlc6hFGqGUJJKTXbUkAloBFeqCKiHB/ZFz8ADs2eM+LKAirR3aNh2VBCjIR/L3IEVV6yviXhup2lXDy00IQVoapKVD27aUk0B5OZSHK7fIraKiqkJMCLntFEpwj0tLobQM0KrlJyZCcvgbQCjBtV/Dy4i0oyJSSZe6n5slQ1IyJIaqKtHy8qjXlpaRfMB93qH9BYhWVFbNqlARbifiPivC2yLyM1q1rPKUFpS2aUdpizRITXW/J0lV33gSBLS4GM3b4z7nwqrPUhOTKGuV7rZXcivK1X1mWlZG6sF8Ug7sIengPrRNG0hvB2ltkVD4n09FBezfh+zZgxTsQUvLKreFiPtsE6T6N19t3oKKtHS0bTqkpiKR9imUV4S3VdT2qfyMI98ew/NUVEAosWrbJSTgfmep/nmHEiEp/A0idOMNJFz87TqSpXYiskJVs2qaFosKfTvuIrwRGeHnAm3tWnjkEfjXvyr/9gEXom3auOo5KwsyMqB1a/eVtbQUli6Ff/7TfWXu0QN+9Su49lro1w8Siva7/wzLlsHWZfDVB65PJDMTLh1D/xdfZPYdj8Ptt7vQGjYWluzl0M23853X5/CdzTdC0R1w110waZL7zv3WW/DEE65RM2fWvVIvvQR33+wa/N57MHCgez4hgYTUVFJFSD38Naqwaxds2ABffknChg20+uor6PJDGD6chMGDSUgO13SlpdX7cqJISgopiYnVqqhYqfk7QeOI5MXhNW7SCWyDacJUtd4bkAmsqWXaCGAB7nf5PODjhixz4MCBGq82bVLt0EG1VSvV665TfeUV1T17VMvKGvb6sjLVnBzVigpVXbNG9Wc/U+3bVzUhQTVc5GmPHm7hr73mXlBRoTpypGpSkmp2tupDD7n5/vIXt9CKCtXFi1Uvv9w9n56uetpp7mcR1VBItbS09ka9/LKb98ILVb/++jg/IWNMYwGytZZcrbfLRUReBIYC7YFdwD2ECw5V/bOICPAn3JEwB4D/0nq6WyB+u1z274cLLnB90MuWQa9edcz8zjsweTI8/zycdVb1aWvXwv33w8svu7J+yBA491zX7zJoELRvf+Ty9uxxe1JUYccO+MEPYNasI/egZmfDAw9Afj6MH+++1v7sZ/DVV9C9+5HLVYX+/d33wk8+cd/njTG+VFeXS4Mq9Ma4+blCLypyVXhuruqBA+FKWl2hfPnlrth9880GLOj++13V27q1q55VVfftU500yVXNLVuq/uY3qrt3N7xxS5a4Sj4zU7WgoGGvee8914633qp5+uuvu+nPPNPwdhhjPEEdFbpnw+f61a5dcM45rgKPSE52BXNKCmzcCNOnu8OOGrSwli3hlFPgu9+F3/4W/vIXyMlxfdz33OMOOzkaF17o+re7dHH94g0Rqco3bqx5+kMPQefOMGbM0bXFGOMrTTbQS0rgqafg4otdbwO4Hofrr3eHEj7xhHuusNDtwNy9291uvRUmTmzgm+za5faKLl4Mw4e7QO/dGz74AM4//9gbP2TI0c3fqZP7r/TVV0dOW7rUHabz6KPW1WJMnGuSgb5+vStGV692VffTT8MNN8D//I/r9v7b3+Cmm2LwRjt3ujNuOnSAhQvdcYpXXOHOVjiREhKgW7eaK/Q//AHS0+GWW05sm4wxMRf4QP/4Y7jxRnck3sCBrutk6lR3GOHzz8Nf/wpjx8Jrr8GcOW7e//qvGL35rl3uwHJwp9tdc02MFnwMevQ4skJftw7mzoXf/c51DRlj4lqgA33tWtfT0bKlO4Fm5kx31uRll8Gzz7ozMUeNgrvvhscfhz59XP94zE67j1ToftC9O7z/vjuiJbKCs2a56n3SJG/bZoyJicAG+qZNbj9ks2aut6N7d3fW1q5dLtwjmZaUBI89Bldf7Q5BbNEiRg04eNAd4/itb8VogcepRw/332zPnqodsdnZ7pTVDjVeb9YYE2cCOR76vn1w6aUuU998s+ogj4QEV5XXVIF/+9sxzt5du9y9nyp0qOpHV3VnpWbVfDirMSb+BDLQ33/f5dZzz8GZR4w+c4Ls3Onu/VKhRwI90o/+9dfun07k9H5jTNwLZKBv3uzuPc0qv1foK1a4ewt0YwIjkIG+ZYs7pNrTLI1U6H4J9ObN3beFSIW+YoXrg2qMQZmNMZ4IbKB36VI1LKwnIhX6SSd52IjD9OhRVaFHdog2P5FjERpjGlMgA33zZjfirKd27XIn7Pjp7Mvu3V2FbjtEjQmkQAb6li1uPHJP7dzpnx2iET16uHFkNm2yHaLGBFDgAr242GWpLyp0v/SfR3Tv7qrzOXPcYwt0YwIlcIG+dau790WF7sdAB5g923aIGhNAgQv0LVvcveeBHjkl1U969HD3y5fbDlFjAihwgR45Bt3TLpeiIjfurt8q9I4dq0LcdogaEziBC/QtW9zVt085xcNGRA5Z9FuFLlLV7WL958YETiADPSMDEr0cdsxvZ4lGs0A3JrACF+i+OAbdb+O4RDvtNPffLnKZJmNMYAQu0H1xDLqfK/S773aXZYrZOMHGGL8I1HjopaWwfbuPAt2P44yfdJK/hiMwxsRMoCr0nBx3EQtfdLm0b++unmGMMSdIoALdV8eg+7G7xRgTaIEK9Mgx6J4Huh/HcTHGBF6gAn3LFneodefOHjfEKnRjjAcCF+gnn+wuDO0pC3RjjAcCFeibN/ugu6Ww0J36b10uxpgTLFCBvmWLD45w8fMx6MaYQAtMoJeXw7ZtPqjQ/XyWqDEm0AIT6Dt2uBOLrEI3xjRVDQp0ERkmIp+LyAYRmVLD9C4islBEPhGRT0Xk+7Fvat18dQw6WIVujDnh6g10EQkB04HhQG9gjIj0Pmy23wKzVfUsYDTwZKwbWh/f5Ghurrtv397bdhhjmpyGVOiDgA2qulFVDwEvASMPm0eB1uGf2wBfx66JDVNc7O5TUk70Ox/mwAF33KSn4/caY5qihgR6J2Bb1OOc8HPR7gVuEJEcYD5wW00LEpHxIpItItm5kUo2RkpK3L3nx6AfOGCXdjPGeCJWO0XHAM+oagbwfeB5ETli2ao6Q1WzVDWrQ4xHIowEui8q9NRUjxthjGmKGhLo24Hok+kzws9FuxmYDaCqHwIpwAntRPZNhX7woFXoxhhPNCTQlwM9RaSbiCTjdnrOPWyercB3AETkDFygx7ZPpR6+CXSr0I0xHqk30FW1DJgEvAGsxx3NslZE7heRK8Oz3QX8RERWAy8C41RVG6vRNYnsFPU80K1CN8Z4pEGHYqjqfNzOzujnfhf18zpgcGybdnRKSiAU8sHBJbZT1BjjkcCcKVpS4oPqHKzLxRjjGQv0WLMuF2OMRwIT6MXFPgl0q9CNMR4JTKBbhW6MaeoCFeien1QEtlPUGOOZQAW6byp063IxxnjAAj2WSkuhrMwqdGOMJwIT6L7YKXrggLu3Ct0Y44HABLov+tAPHnT3VqEbYzwQqEC3Ct0Y05RZoMeSVejGGA8FJtB91YdugW6M8UBgAt1XFbp1uRhjPBCoQPd8p6hV6MYYDwUq0D2v0G2nqDHGQxbosWQ7RY0xHgpEoKv6JNCty8UY46FABPqhQ+7e8z502ylqjPFQIALdVxeIBqvQjTGesECPpYMHQcQHDTHGNEWBCPTiYnfveY5GrlYk4nFDjDFNUSACPVKhe96HbpefM8Z4KFCB7nmFbpefM8Z4yAI9luzyc8YYDwUi0H3Th26XnzPGeCgQgW4VujHGBCzQbaeoMaYpC1Sge16h205RY4yHLNBjySp0Y4yHAhHovtopahW6McYjDQp0ERkmIp+LyAYRmVLLPD8SkXUislZEXohtM+vmqz50C3RjjEcS65tBRELAdOAyIAdYLiJzVXVd1Dw9gf8DDFbVfBE5qbEaXBPfdLnYYYvGGA81pEIfBGxQ1Y2qegh4CRh52Dw/Aaaraj6Aqn4T22bWzReBrmoVujHGUw0J9E7AtqjHOeHnop0GnCYiH4jIRyIyrKYFich4EckWkezc3Nxja3ENfNGHXlLiQt0qdGOMR2K1UzQR6AkMBcYAT4tI28NnUtUZqpqlqlkdOnSI0VtXVejJyTFb5NGzy88ZYzzWkEDfDnSOepwRfi5aDjBXVUtVdRPwBS7gT4jI5ec8HbXWLm5hjPFYQwJ9OdBTRLqJSDIwGph72Dyv4apzRKQ9rgtmY+yaWTdfXE/ULj9njPFYvYGuqmXAJOANYD0wW1XXisj9InJleLY3gDwRWQcsBO5W1bzGavThfBHoVqEbYzxW72GLAKo6H5h/2HO/i/pZgTvDtxOuuNgHgW4VujHGY4E4U7SkxCcnFYFV6MYYzwQm0D2v0COBbhW6McYjFuixYoctGmM8FohA90UfunW5GGM8FohA91WFbl0uxhiPBCbQbaeoMaapC0ygW4VujGnqLNBj5cABCIUgKcnjhhhjmqpABLpvdoo2b+7xgDLGmKYsEIHuiz50u7iFMcZjgQl031ToxhjjEQv0WLEK3RjjsUAEuq/60I0xxiNxH+hlZVBR4YM+9AMHrEI3xngq7gPdFxeIBtflYhW6McZDFuixYl0uxhiPxX2gFxe7e88D3XaKGmM8FveBbhW6McY4gQl0z3eKWoVujPFYYALdKnRjTFNngR4LFRWuM98qdGOMh+I+0H2xUzTSCKvQjTEeivtA90Uful3cwhjjA4EJdE8rdLu4hTHGByzQY8EqdGOMD8R9oPuiD90qdGOMD8R9oFuFbowxTmAC3XaKGmOausAEunW5GGOaOgv0WLAK3RjjA3Ef6LZT1BhjnAYFuogME5HPRWSDiEypY74fioiKSFbsmli3khJITIRQ6ES9Yw2sQjfG+EC9gS4iIWA6MBzoDYwRkd41zNcKmAwsi3Uj6+KbC0SDVejGGE81pEIfBGxQ1Y2qegh4CRhZw3z/A/wBKI5h++rli0CPVOgW6MYYDzUk0DsB26Ie54SfqyQiZwOdVfX1uhYkIuNFJFtEsnNzc4+6sTUpLvZJoCcnu74fY4zxyHHvFBWRBOAR4K765lXVGaqapapZHTp0ON63BnxSodvFLYwxPtCQQN8OdI56nBF+LqIVcCbwnohsBs4D5p6oHaMlJT64WlFhIbRs6XEjjDFNXUMCfTnQU0S6iUgyMBqYG5moqntVtb2qZqpqJvARcKWqZjdKiw/jiwrdAt0Y4wP1BrqqlgGTgDeA9cBsVV0rIveLyJWN3cD6WKAbY4zToL14qjofmH/Yc7+rZd6hx9+shvPFTlELdGOMD8T9maK+6EMvKrJAN8Z4LhCB7osKvUULjxthjGnqLNBjwbpcjDE+EPeBbn3oxhjjxH2ge96HrmqBbozxhUAEuqcV+qFDUFZmgW6M8ZwF+vEqLHT3FujGGI9ZoB8vC3RjjE/EdaBXVLgeDwt0Y4yJ80A/dMjde7pT1ALdGOMTcR3ovrhAdFGRu7dAN8Z4zAL9eEUqdDtT1BjjsbgO9OLwxe58EehWoRtjPBbXgR6p0K0P3RhjAhLoVqEbY4wF+vGzPnRjjE/EdaD7pg89NRVCIQ8bYYwxcR7ovqnQrbvFGOMDgQh0z3eKWqAbY3wgEIFuFboxxligHz8LdGOMT8R1oPtip2hRkR3hYozxhbgO9AMH3H3z5h42wip0Y4xPxHWgFxS4+7Q0DxthgW6M8Ym4D/RmzewoF2OMgQAEetu2HjfCAt0Y4xNxHej5+R4Henm568i3QDfG+EBcB7rnFXpkr6wFujHGByzQj4eNtGiM8REL9ONhgW6M8ZEGBbqIDBORz0Vkg4hMqWH6nSKyTkQ+FZF3RKRr7Jt6pIICHxyyCBboxhhfqDfQRSQETAeGA72BMSLS+7DZPgGyVLUf8ArwcKwbejhVH1TokQtE25mixhgfaEiFPgjYoKobVfUQ8BIwMnoGVV2oquE9hHwEZMS2mUc6eBBKS63LxRhjIhoS6J2AbVGPc8LP1eZmYEFNE0RkvIhki0h2bm5uw1tZg8hZohboxhjjxHSnqIjcAGQBf6xpuqrOUNUsVc3q0KHDcb2XBboxxlSX2IB5tgOdox5nhJ+rRkQuBX4DfFtVS2LTvNpZoBtjTHUNqdCXAz1FpJuIJAOjgbnRM4jIWcBfgCtV9ZvYN/NIFujGGFNdvYGuqmXAJOANYD0wW1XXisj9InJleLY/Ai2Bl0VklYjMrWVxMeObQA+FPB6Q3RhjnIZ0uaCq84H5hz33u6ifL41xu+rlm0Bv2RJEPGyEMcY4cXumaH6+u2/TxsNG2EiLxhgfidtALyhw46DbWOjGGOPEdaB7PhZ6UZEFujHGNyzQj0dhoZ32b4zxDQv042FdLsYYH4nrQPd0pEWwQDfG+EqDDlv0o4IC6NmzkRb+ySfQrh106VL3fBbo5hiVlpaSk5NDcXGx100xPpWSkkJGRgZJSUkNfk1cB3qjdblccQVcdBG88ELd81mgm2OUk5NDq1atyMzMROw8BnMYVSUvL4+cnBy6devW4NfFZZdLo46FnpcH27fDpk31N8IC3Ryj4uJi2rVrZ2FuaiQitGvX7qi/wcVloB84AGVljRToa9e6+61b657v0CHXCAt0c4wszE1djuX3Iy4DvVFP+48E+o4dLrRrYwNzGWN8xgL9cJFAV4WcnNrns0A3ce7BBx+kT58+9OvXjwEDBrBs2TKvm3TCbd68mRei9pVlZ2fz85//3MMWHZ+43Cna6IGemOi6U7Zuhe7da57PAt3EsQ8//JB58+axcuVKmjVrxu7duzlU1zfSBigrKyMx0btIOZb3jwT6ddddB0BWVhZZWVmN0bwTIi4DPTIwV6MF+uDBsGhR3f3odoFoEyO33w6rVsV2mQMGwGOP1T59x44dtG/fnmbhoZ/bt29fOW358uVMnjyZoqIimjVrxjvvvENSUhITJkwgOzubxMREHnnkES6++GKeeeYZ5syZQ2FhIeXl5cyfP5/bbruNNWvWUFpayr333svIkdUuQUxhYSEjR44kPz+f0tJSHnjgAUaOHMnmzZsZNmwYAwcOZOXKlfTp04fnnnuO5s2bk5mZyY9+9CMWLFhAamoqL7zwAqeeeirjxo0jJSWFTz75hMGDB3Prrbdy6623kpubS/PmzXn66ac5/fTTGTduHK1btyY7O5udO3fy8MMPc8011zBlyhTWr1/PgAEDuPHGGznrrLOYOnUq8+bNY9GiRUyePBlw/dmLFy+msLCQUaNGsW/fPsrKynjqqacYMmQIEyZMYPny5Rw8eJBrrrmG++67D4D58+dz55130qJFCwYPHszGjRuZN28eRUVF9X5Ox8K6XKJ98w3k5sKwYe5xXYFuFbqJY9/97nfZtm0bp512GhMnTmTRokUAHDp0iFGjRvH444+zevVq3n77bVJTU5k+fToiwn/+8x9efPFFbrzxxsojMFauXMkrr7zCokWLePDBB7nkkkv4+OOPWbhwIXfffTdFkeInLCUlhVdffZWVK1eycOFC7rrrLlQVgM8//5yJEyeyfv16WrduzZNPPln5ujZt2vCf//yHSZMmcfvtt1c+n5OTw9KlS3nkkUcYP348TzzxBCtWrGDq1KlMnDixcr4dO3bw/vvvM2/ePKZMmQLAQw89xJAhQ1i1ahV33HFHtXZOnTqV6dOns2rVKpYsWVL5j+R73/seq1atYvXq1QwYMABw3VfZ2dl8+umnLFq0iE8//ZTi4mJ++tOfsmDBAlasWEH0dZQb8jkdi7is0Bst0CP952efDR07WqCbE6KuSrqxtGzZkhUrVrBkyRIWLlzIqFGjeOihhxg4cCAnn3wy55xzDgCtW7cG4P333+e2224D4PTTT6dr16588cUXAFx22WWkp6cD8OabbzJ37lymTp0KuMMzt27dyhlnnFH53qrKr3/9axYvXkxCQgLbt29n165dAHTu3JnBgwcDcMMNNzBt2jR+8YtfADBmzJjK++jwvfbaawmFQhQWFrJ06VKuvfbaymklJVVXw7zqqqtISEigd+/ele9Xl8GDB3PnnXdy/fXX84Mf/ICMjAzOOeccbrrpJkpLS7nqqqsqA3327NnMmDGDsrIyduzYwbp166ioqKB79+6Vx5GPGTOGGTNmNPhzOhZxHegxHws9Euh9+rizRC3QTYCFQiGGDh3K0KFD6du3L88++ywDBw486uW0iOp2VFX++c9/0qtXr1rnnzlzJrm5uaxYsYKkpCQyMzMrq/3DD9WLflzbz5H3r6iooG3btqyqpf+qWdSVxSLfCOoyZcoURowYwfz58xk8eDBvvPEGF110EYsXL+b1119n3Lhx3HnnnQwZMoSpU6eyfPly0tLSGDduXL3HjzfkczoWcdvlkpraCFd+W7vW/Zc45RQLdBNon3/+OV9++WXl41WrVtG1a1d69erFjh07WL58OQD79++nrKyMIUOGMHPmTAC++OILtm7dWmMYfe973+OJJ56oDMxPPvnkiHn27t3LSSedRFJSEgsXLmTLli2V07Zu3cqHH34IwAsvvMCFF15YOW3WrFmV9+eff/4Ry23dujXdunXj5ZdfBlxorl69us7PoVWrVuzfv7/GaV999RV9+/blV7/6Feeccw6fffYZW7ZsoWPHjvzkJz/hlltuYeXKlezbt48WLVrQpk0bdu3axYIFCwDo1asXGzduZPPmzdXa39DP6VjEbYXeaDtEzzzTXVKuSxdYsMAdvljTAf4W6CaOFRYWctttt1FQUEBiYiKnnnoqM2bMIDk5mVmzZnHbbbdx8OBBUlNTefvtt5k4cSITJkygb9++JCYm8swzz1SreCP++7//m9tvv51+/fpRUVFBt27dmDdvXrV5rr/+eq644gr69u1LVlYWp59+euW0Xr16MX36dG666SZ69+7NhAkTKqfl5+fTr18/mjVrxosvvljjes2cOZMJEybwwAMPUFpayujRo+nfv3+tn0O/fv0IhUL079+fcePGcdZZZ1VOe+yxx1i4cCEJCQn06dOH4cOH89JLL/HHP/6RpKQkWrZsyXPPPUe3bt0466yzOP3006t1GaWmpvLkk08ybNgwWrRoUdmN1dDP6Zioqie3gQMH6rH64Q9Ve/c+5pfXrKJCNT1ddfx49/jRR1VBdffumue/7z43vawsxg0xTcG6deu8boLvbNq0Sfv06VPjtK5du2pubu4JbtHx279/v6qqVlRU6IQJE/SRRx45qtfX9HsCZGstuRq3XS4xr9B37YI9e1z/OVSNtFhbt0thoev3CYVi3BBjTFA8/fTTDBgwgD59+rB3715++tOfNur7xW2XS8eOMV7omjXuvqZAj/oaVskG5jImpjIzM1kT+Ts8TKQfOt7ccccdRxwO2ZisQo+IPsIF6q/Q9+yxQDfG+IoFesTatZCeXlX6d+gAKSk1B3p5Obz7Lpx7bowbYYwxxy7uAr3RxkKPPsIFqo50qSnQP/rInVF61VUxboQxxhy7uAv0oiJXIMc00AsKYPVq6Nu3+vO1Bfprr0FSEgwfHsNGGGPM8Ym7QG+UgbmmTXP/KW6+ufrzNQW6qgv0Sy6B8GnRxsSjeBk+d/PmzZx55plA3cPbZmZmsnv37jqX9fvf/77a4wsuuCA2jfSJuDvKJebjuBQUwKOPuu6Tw49m6dKl6kIXycnuufXrYcMGuOuuGDXAmBMvXofPPd7hbX//+9/z61//uvLx0qVLY9Es37BAnzbNLfR3vztyWpcuVRe6iIyL/tpr7v7KK2PUANPkeTB+rpfD544ePZqxY8cyYsQIAMaNG8fll19OVlYWY8eOrRx18E9/+tMRFfR7771XObxtXl4eY8aMYfv27Zx//vnVxme56qqr2LZtG8XFxUyePJnx48czZcoUDh48WHlc+MyZM2nZsiWFhYWoKr/85S9ZsGABIsJvf/tbRo0axXvvvce9995L+/btWbNmDQMHDuR///d/fXv5wLjrcjmuQF+7FjIyXNdKfn7d1TnUfOjia6/BoEFuvBdj4pSXw+eOGjWK2bNnV77fO++8w4gRIzjppJN46623WLlyJbNmzar3ykH33XcfF154IWvXruXqq69ma9Tf6d///ndWrFhBdnY206ZNIy8vj4ceeojU1FRWrVpVOS5NxJw5cyqHxH377be5++672bFjB+DGWXnsscdYt24dGzdu5IMPPji+D78RNZ0KPS/PVdVFRfDss/D663D++bVX53BkoG/fDsuXw2H9cMYcFw/Gz/Vy+Nzhw4czefJkSkpK+Pe//81FF11Eamoqe/fuZdKkSaxatYpQKFS5/NosXryYOXPmADBixAjS0tIqp02bNo1XX30VgG3btvHll1/Srl27Wpf1/vvvM2bMGEKhEB07duTb3/42y5cvp3Xr1gwaNIiMjAwABgwYwObNm6sNGuYnDQp0ERkGPA6EgL+q6kOHTW8GPAcMBPKAUaq6ObZNdRoU6CUl7mIVGRnu8MPSUrj2Wtd1smiRG6bxlltctV1bdQ7u9VAV6HPnuvsYXFnEGK95NXxuSkoKQ4cO5Y033mDWrFmMHj0agEcffZSOHTuyevVqKioqSElJOfqVwnXLvP3223z44Yc0b96coUOH1jucbV2iByELhUKUlZUd87IaW71dLiISAqYDw4HewBgR6X3YbDcD+ap6KvAo8IdYNzSieXPodZrSZt82eOUVuOcemDQJrrsOLr0UMjPdGCtdukCnTnDTTTB2LCxcCE8/Deed5wJ82TJ44QV46qna3yw1FU46CebMgYsvhp//HHr1guMchN4Yr3k5fC64bpd//OMfLFmyhGHhK4Tt3buXk08+mYSEBJ5//nnKy8vrXIeLLrqo8gLPCxYsID98CNzevXtJS0ujefPmfPbZZ3z00UeVr0lKSqK0tPSIZQ0ZMoRZs2ZRXl5Obm4uixcvZtCgQXW+vx81pEIfBGxQ1Y0AIvISMBJYFzXPSODe8M+vAH8SEdHovRQxcjN/4+b9/w2nuv4tRCAtzZ3l2a6dux7ouHHQvj0sWQKvvurK+l/8An7846oFJSZC+AooderdG957D/r1c0e23HJLzcPpGhNHvBw+F1wf/tixYxk5ciTJ4SPIJk6cyA9/+EOee+65yiFn63LPPfcwZswY+vTpwwUXXECXcBfpsGHD+POf/8wZZ5xBr169OO+88ypfM378ePr168fZZ59drR/96quv5sMPP6R///6ICA8//DDf+ta3+Oyzz47p8/WK1Je5InINMExVbwk/Hgucq6qTouZZE54nJ/z4q/A8uw9b1nhgPECXLl0GRg9s32Cvvw4vvuhOuz/3XOjfv+4rXZSVwRdfuKr6WII4Px8OHrSdoCam1q9ff9yXGzPBV9PviYisUNUaj908oTtFVXUGMAMgKyvr2Kr3ESPcraESE12VfazS0tzNGGN8riGHLW4HOkc9zgg/V+M8IpIItMHtHDXGGHOCNCTQlwM9RaSbiCQDo4G5h80zF7gx/PM1wLuN0X9uTJDYn4ipy7H8ftQb6KpaBkwC3gDWA7NVda2I3C8ikdMl/wa0E5ENwJ3AlKNuiTFNSEpKCnl5eRbqpkaqSl5e3lEfulnvTtHGkpWVpdnZ2Z68tzFeKy0tJScn57iOjzbBlpKSQkZGBklJSdWe981OUWOMk5SURLdu3bxuhgmYuBvLxRhjTM0s0I0xJiAs0I0xJiA82ykqIrnAMZwqCkB7oO5LkwRTU1zvprjO0DTXuymuMxz9endV1Q41TfAs0I+HiGTXtpc3yJriejfFdYamud5NcZ0htuttXS7GGBMQFujGGBMQ8RroM7xugEea4no3xXWGprneTXGdIYbrHZd96MYYY44UrxW6McaYw1igG2NMQMRdoIvIMBH5XEQ2iEggR3UUkc4islBE1onIWhGZHH4+XUTeEpEvw/eBu/KGiIRE5BMRmRd+3E1EloW396zwEM6BIiJtReQVEflMRNaLyPlNZFvfEf79XiMiL4pIStC2t4j8XUS+CV/VLfJcjdtWnGnhdf9URM4+2veLq0Bv4AWrg6AMuEtVewPnAbeG13MK8I6q9gTeIZjDFE/GDdMc8Qfg0fAFyPNxFyQPmseBf6vq6UB/3PoHeluLSCfg50CWqp4JhHDXWgja9n4GGHbYc7Vt2+FAz/BtPFDHFexrFleBTtQFq1X1EBC5YHWgqOoOVV0Z/nk/7g+8E25dnw3P9ixwlScNbCQikgGMAP4afizAJbgLj0Mw17kNcBHumgKo6iFVLSDg2zosEUgNX+WsObCDgG1vVV0M7Dns6dq27UjgOXU+AtqKyMlH837xFuidgG1Rj3PCzwWWiGQCZwHLgI6quiM8aSfQ0at2NZLHgF8CFeHH7YCC8EVWIJjbuxuQC/wj3NX0VxFpQcC3tapuB6YCW3FBvhdYQfC3N9S+bY873+It0JsUEWkJ/BO4XVX3RU8LX+IvMMecisjlwDequsLrtpxgicDZwFOqehZQxGHdK0Hb1gDhfuORuH9opwAtOLJrIvBivW3jLdAbcsHqQBCRJFyYz1TVOeGnd0W+goXvv/GqfY1gMHCliGzGdaVdgutbbhv+Sg7B3N45QI6qLgs/fgUX8EHe1gCXAptUNVdVS4E5uN+BoG9vqH3bHne+xVugN+SC1XEv3Hf8N2C9qj4SNSn6Ytw3Av860W1rLKr6f1Q1Q1Uzcdv1XVW9HliIu/A4BGydAVR1J7BNRHqFn/oOsI4Ab+uwrcB5ItI8/PseWe9Ab++w2rbtXODH4aNdzgP2RnXNNIyqxtUN+D7wBfAV8Buv29NI63gh7mvYp8Cq8O37uD7ld4AvgbeBdK/b2kjrPxSYF/65O/AxsAF4GWjmdfsaYX0HANnh7f0akNYUtjVwH/AZsAZ4HmgWtO0NvIjbR1CK+zZ2c23bFhDcUXxfAf/BHQF0VO9np/4bY0xAxFuXizHGmFpYoBtjTEBYoBtjTEBYoBtjTEBYoBtjTEBYoBtjTEBYoBtjTED8f+NMTD+aVpnpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scores(train):\n",
    "    accuracy = train.history['accuracy']\n",
    "    val_accuracy = train.history['val_accuracy']\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_loss(train):\n",
    "    loss = train.history['loss']\n",
    "    val_loss = train.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'b', label='Loss apprentissage')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Loss validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_scores(trained)\n",
    "plot_loss(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de6eef-daa1-4f6f-809f-eae817e70bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
