{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed86aefc-f6d0-455d-9aef-bc0b5681cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a213c9-c03b-4f1b-a3a0-6e5333383da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba48d5e6-43f0-4a79-bdf1-366aac61855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/data_palm_vein/NIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80a1917-c1d2-4516-880e-08a5ce908649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================= Training parameters ================= \n",
      "\n",
      "            Epochs :  12   |   Batch size : 32 \n",
      "\n",
      " ======================================================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "batch = 32\n",
    "\n",
    "print(\"\\n ================= Training parameters ================= \\n\")\n",
    "print(\"            Epochs :  {}   |   Batch size : {} \".format(epochs, batch))\n",
    "print(\"\\n ======================================================= \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce62474-4908-4ad6-8814-4b41795aa7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 4800 files for training.\n",
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5debb970-fb86-42a9-849c-a718730905ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 1200 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa40884-9307-4a6f-81ba-08fc22e677a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 500 classes.\n",
      "Using 900 files for validation.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fee9419-11d0-4dff-a970-3c51a684fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_tf, input_shape=(128, 128, 3), classes=500):\n",
    "    if model_tf == 'resnet150v2': \n",
    "        model_transferlearning = ResNet152V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_tf == 'resnet50v2':\n",
    "        model_transferlearning = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_tf == 'vgg16':\n",
    "        model_transferlearning = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_tf == 'vgg19':\n",
    "        model_transferlearning = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_tf == 'inceptionresnetv2':\n",
    "        model_transferlearning = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_tf == 'xception':\n",
    "        model_transferlearning = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model_transferlearning.tbatch_sizenable = False\n",
    "    model = Sequential()\n",
    "    model.add(model_transferlearning)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2048, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cd1f89-d286-4a2a-94ba-40687f2a485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_models = [\"resnet150v2\", \"resnet50v2\",\"vgg16\", \"vgg19\", \"inceptionresnetv2\", \"xception\"]\n",
    "\n",
    "list_models = [\"resnet150v2\", \"resnet50v2\",\"vgg16\", \"vgg19\"]\n",
    "list_accuracy = []\n",
    "list_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c38539-3f7c-40d1-a98c-00401c8b6d42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152v2 (Functional)     (None, 4, 4, 2048)        58331648  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               1024500   \n",
      "=================================================================\n",
      "Total params: 201,968,628\n",
      "Trainable params: 201,824,884\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/12\n",
      "150/150 [==============================] - 356s 2s/step - loss: 6.1753 - accuracy: 0.0219 - val_loss: 10.2156 - val_accuracy: 0.0017\n",
      "Epoch 2/12\n",
      "150/150 [==============================] - 804s 5s/step - loss: 3.1173 - accuracy: 0.3535 - val_loss: 7.6390 - val_accuracy: 0.0533\n",
      "Epoch 3/12\n",
      "150/150 [==============================] - 372s 2s/step - loss: 0.8653 - accuracy: 0.7848 - val_loss: 14.6841 - val_accuracy: 0.0567\n",
      "Epoch 4/12\n",
      "150/150 [==============================] - 9992s 67s/step - loss: 0.6099 - accuracy: 0.8502 - val_loss: 9.9424 - val_accuracy: 0.0950\n",
      "Epoch 5/12\n",
      "150/150 [==============================] - 281s 2s/step - loss: 0.3579 - accuracy: 0.9081 - val_loss: 10.6714 - val_accuracy: 0.1183\n",
      "Epoch 6/12\n",
      "150/150 [==============================] - 281s 2s/step - loss: 0.3524 - accuracy: 0.9173 - val_loss: 8.6921 - val_accuracy: 0.2100\n",
      "Epoch 7/12\n",
      "150/150 [==============================] - 281s 2s/step - loss: 0.2578 - accuracy: 0.9373 - val_loss: 7.1087 - val_accuracy: 0.4100\n",
      "Epoch 8/12\n",
      "150/150 [==============================] - 283s 2s/step - loss: 0.5358 - accuracy: 0.8977 - val_loss: 71.8639 - val_accuracy: 0.0067\n",
      "Epoch 9/12\n",
      "150/150 [==============================] - 307s 2s/step - loss: 0.4140 - accuracy: 0.9196 - val_loss: 26.0612 - val_accuracy: 0.0800\n",
      "Epoch 10/12\n",
      "150/150 [==============================] - 289s 2s/step - loss: 0.3507 - accuracy: 0.9356 - val_loss: 25.7375 - val_accuracy: 0.0200\n",
      "Epoch 11/12\n",
      "150/150 [==============================] - 287s 2s/step - loss: 0.2556 - accuracy: 0.9492 - val_loss: 62.8032 - val_accuracy: 0.0225\n",
      "Epoch 12/12\n",
      "150/150 [==============================] - 287s 2s/step - loss: 0.2184 - accuracy: 0.9544 - val_loss: 8.6602 - val_accuracy: 0.3342\n",
      "29/29 - 8s - loss: 8.6005 - accuracy: 0.3278\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Functional)      (None, 4, 4, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               1024500   \n",
      "=================================================================\n",
      "Total params: 167,201,780\n",
      "Trainable params: 167,156,340\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/12\n",
      "150/150 [==============================] - 177s 1s/step - loss: 5.7324 - accuracy: 0.0712 - val_loss: 6.7635 - val_accuracy: 0.0025\n",
      "Epoch 2/12\n",
      "150/150 [==============================] - 169s 1s/step - loss: 1.9207 - accuracy: 0.5877 - val_loss: 14.2411 - val_accuracy: 0.0308\n",
      "Epoch 3/12\n",
      "150/150 [==============================] - 167s 1s/step - loss: 0.8078 - accuracy: 0.8181 - val_loss: 25.4286 - val_accuracy: 0.0033\n",
      "Epoch 4/12\n",
      "150/150 [==============================] - 166s 1s/step - loss: 0.7937 - accuracy: 0.8452 - val_loss: 25.9041 - val_accuracy: 0.0150\n",
      "Epoch 5/12\n",
      "150/150 [==============================] - 167s 1s/step - loss: 0.3679 - accuracy: 0.9171 - val_loss: 9.4571 - val_accuracy: 0.1033\n",
      "Epoch 6/12\n",
      "150/150 [==============================] - 169s 1s/step - loss: 0.6466 - accuracy: 0.8838 - val_loss: 51.9893 - val_accuracy: 0.0025\n",
      "Epoch 7/12\n",
      "150/150 [==============================] - 167s 1s/step - loss: 1.0390 - accuracy: 0.8613 - val_loss: 96.0205 - val_accuracy: 0.0092\n",
      "Epoch 8/12\n",
      "150/150 [==============================] - 3728s 25s/step - loss: 0.8821 - accuracy: 0.8883 - val_loss: 23.5661 - val_accuracy: 0.0883\n",
      "Epoch 9/12\n",
      " 69/150 [============>.................] - ETA: 1:27 - loss: 0.7569 - accuracy: 0.9198"
     ]
    }
   ],
   "source": [
    "for model_tf in list_models:\n",
    "    #clear_output(wait=True)\n",
    "    model = create_model(model_tf)\n",
    "    trained = model.fit(train_ds, validation_data = val_ds, epochs=epochs, batch_size=batch)\n",
    "    val = model.evaluate(test_ds, verbose=2)\n",
    "    acc = val[1] * 100\n",
    "    loss = val[0] * 100\n",
    "    list_accuracy.append(acc)\n",
    "    list_loss.append(loss)\n",
    "#    with open('/trainHistoryDict', 'wb') as file_pi:\n",
    "#        pickle.dump(trained.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036ceba-8762-4a0e-ac55-512864061895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Models': list_models, 'ACCURACY (%)': list_accuracy, 'LOSS (%)': list_loss})\n",
    "df = df.sort_values(by=['ACCURACY (%)'])\n",
    "df = df.reset_index(drop=True)\n",
    "#df = df.set_title(\"Epochs :  {} | Batch_size : {} | Optimizer : Nadam\".format(epochs, batch))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27691eb2-568f-4319-9816-4bf9a7fe8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8, 2))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.table(cellText = df.values,\n",
    "          rowLabels = df.index,\n",
    "          colLabels = df.columns,\n",
    "          loc = \"center\"\n",
    "         )\n",
    "ax.set_title(\"Epochs :  {} | Batch_size : {} | Optimizer : Nadam\".format(epochs, batch))\n",
    "\n",
    "ax.axis(\"off\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0d798-8099-4ab7-aca1-2880a3d1ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Bar(x = df.iloc[:,0].tolist(), y = df.iloc[:,1].tolist())\n",
    "\n",
    "data1 = [trace1]\n",
    "layout1 = go.Layout(\n",
    "    title='Comparison of the Learning Methods',\n",
    "    xaxis=dict(titlefont=dict(size=16)),\n",
    "    yaxis=dict(title='ACCURACY (%)',gridwidth=1, gridcolor='#bdbdbd', range=[89, 99]),\n",
    "    font=dict(size=16),\n",
    "    bargap = 0.7,\n",
    "    barmode='group')\n",
    "\n",
    "fig = go.Figure(data=data1, layout=layout1)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8f75d75-5f0e-4213-817e-6d7353a41aae",
   "metadata": {},
   "source": [
    "trained = model.fit(datasets, validation_data = datasets, epochs=epochs, batch_size=batch)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a993fac-9956-4261-9d5c-de51de3a5167",
   "metadata": {},
   "source": [
    "val = model.evaluate(datasets)\n",
    "#y_pred = model.predict(datasets)\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "print(\"\\n ================= Evaluation : Resnet model ================= \\n\")\n",
    "print(\"  With : \\n\")\n",
    "print(\"Batch size         :  {}     |   Epochs      : {} \".format(batch, epochs))\n",
    "print(\"Nombres de classes :  {}    |   Input shape : {} \\n\".format(len(train.class_names), input_shape))\n",
    "print(\"\\n ============================================================= \\n\")\n",
    "\n",
    "print(\"  Results : \\n\")\n",
    "print(\"Loss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77acffe-b5f6-45a7-ae31-4c51c2fafb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
