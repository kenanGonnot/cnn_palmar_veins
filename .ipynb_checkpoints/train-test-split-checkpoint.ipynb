{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ecaedc1-4d10-4a2d-8f1e-8003f059f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "import random\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea59384-b27b-4d15-ae96-4daf098bfa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.random.set_seed(0)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df462554-bf4f-492c-906a-db24d55d3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/data_palm_vein/NIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a561609b-97e3-4e61-9ab7-dfe05eef9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img3(path, xdim=128, ydim=128):\n",
    "    label_names = []\n",
    "    nmax = 6000\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    count = 0\n",
    "    count_split = 1\n",
    "    identity = -1\n",
    "    #print(\"Loading images...\")\n",
    "    for dirname in tqdm_notebook(os.listdir(path), desc=\"Loading images...\"):\n",
    "        if dirname == \".DS_Store\": continue\n",
    "        #print(\"dirname : \", dirname)\n",
    "        label_names.append(dirname)\n",
    "        data_path = os.path.join(path + \"/\" + dirname, '*g')\n",
    "        files = glob.glob(data_path)\n",
    "        identity += 1\n",
    "        if count > nmax: break\n",
    "        for f1 in files:\n",
    "            #print(\"files : \", f1)\n",
    "            img = cv2.imread(f1)\n",
    "            #img = cv2.imread(f1, cv2.IMREAD_GRAYSCALE)\n",
    "            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #img = cv2.imread(f1, 0)\n",
    "            #img = cv2.resize(img, (xdim, ydim))\n",
    "            if count_split <= 4 : \n",
    "                X_train.append(np.array(img))\n",
    "                y_train.append(identity)\n",
    "            elif count_split == 5:\n",
    "                X_test.append(np.array(img))\n",
    "                y_test.append(identity)\n",
    "            elif count_split == 6:\n",
    "                X_val.append(np.array(img))\n",
    "                y_val.append(identity)\n",
    "                count_split = 0\n",
    "            count += 1\n",
    "            #print(\"count_split\", count_split)\n",
    "            count_split += 1\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    print(\"\\n ============================== Data extract - SUMMARY ============================== \\n\")\n",
    "    print(\"\\nX_train.shape =  {}   |   y_train.shape =  {}  \\n\".format(X_train.shape, y_train.shape))\n",
    "    print(\"X_test.shape  =  {}   |   y_test.shape  =  {}  \\n\".format(X_test.shape, y_test.shape))\n",
    "    print(\"X_val.shape   =  {}   |   y_val.shape   =  {}  \\n\".format(X_val.shape, y_val.shape))\n",
    "    print(\"\\n     ----------------------------------------------------------------------- \\n\")\n",
    "    print(count, ' images lues')\n",
    "    print(\"\\nSize of train      :  %.2f%%\" % ((X_train.shape[0] / count)*100))\n",
    "    print(\"\\nSize of test       :  %.2f%%\" % ((X_test.shape[0] / count)*100))\n",
    "    print(\"\\nSize of validation :  %.2f%%\" % ((X_val.shape[0] / count)*100))\n",
    "    gc.collect()\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b6a6d50-3421-4f24-bfe2-c891d607a6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecf226e84964fd6bef4be26afa9a161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images...:   0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================== Data extract - SUMMARY ============================== \n",
      "\n",
      "\n",
      "X_train.shape =  (4000, 128, 128)   |   y_train.shape =  (4000,)  \n",
      "\n",
      "X_test.shape  =  (1000, 128, 128)   |   y_test.shape  =  (1000,)  \n",
      "\n",
      "X_val.shape   =  (1000, 128, 128)   |   y_val.shape   =  (1000,)  \n",
      "\n",
      "\n",
      "     ----------------------------------------------------------------------- \n",
      "\n",
      "6000  images lues\n",
      "\n",
      "Size of train      :  66.67%\n",
      "\n",
      "Size of test       :  16.67%\n",
      "\n",
      "Size of validation :  16.67%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val, label_names = load_img3(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a3415f-377e-49be-bfc1-9e29c8d91143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================== Preprocessing data ============================== \n",
      "\n",
      "X_train.shape =  (4000, 128, 128, 1)   |   y_train.shape =  (4000, 500)  \n",
      "\n",
      "X_test.shape  =  (1000, 128, 128, 1)   |   y_test.shape  =  (1000, 500)  \n",
      "\n",
      "X_val.shape   =  (1000, 128, 128, 1)   |   y_val.shape   =  (1000, 500)  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "X_test = X_test / 255.\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "X_val = X_val / 255.\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n ============================== Preprocessing data ============================== \\n\")\n",
    "print(\"X_train.shape =  {}   |   y_train.shape =  {}  \\n\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test.shape  =  {}   |   y_test.shape  =  {}  \\n\".format(X_test.shape, y_test.shape))\n",
    "print(\"X_val.shape   =  {}   |   y_val.shape   =  {}  \\n\".format(X_val.shape, y_val.shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa013270-d92d-4c01-a60d-86a3b2eaa62f",
   "metadata": {},
   "source": [
    "data_train = list(zip(X_train, y_train))\n",
    "random.shuffle(data_train)\n",
    "X_train, y_train = zip(*data_train)\n",
    "\n",
    "data_test = list(zip(X_test, y_test))\n",
    "random.shuffle(data_test)\n",
    "X_test, y_test = zip(*data_test)\n",
    "\n",
    "data_val = list(zip(X_val, y_val))\n",
    "random.shuffle(data_val)\n",
    "X_val, y_val = zip(*data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b141e89-991a-43eb-90ff-ed0963533af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test,y_test = shuffle(X_test, y_test, random_state=0)\n",
    "X_val,y_val = shuffle(X_val, y_val, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5151d28b-8c8a-431b-87ae-3f6fbe1cf29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "def resnet_model_tf(input_shape=(128, 128, 1), nombre_classes=11):\n",
    "    resnet = ResNet152V2(weights=None, include_top=False, input_shape=input_shape)\n",
    "    resnet.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3324701-212e-4e0d-8352-660e0eeefd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152v2 (Functional)     (None, 4, 4, 2048)        58325376  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               512500    \n",
      "=================================================================\n",
      "Total params: 92,393,332\n",
      "Trainable params: 34,067,956\n",
      "Non-trainable params: 58,325,376\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_resnet = resnet_model_tf(nombre_classes=y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da3677-6e2d-4934-98aa-0b6970bc8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 55s 422ms/step - loss: 6.2453 - accuracy: 0.0010 - val_loss: 6.2146 - val_accuracy: 0.0020\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 52s 414ms/step - loss: 6.2165 - accuracy: 0.0000e+00 - val_loss: 6.2146 - val_accuracy: 0.0020\n",
      "Epoch 3/5\n",
      " 25/125 [=====>........................] - ETA: 35s - loss: 6.2148 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "trained_model_resnet = model_resnet.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932eec5b-3a19-4d64-b780-a863d36f1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model_resnet.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\nLoss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c71ec0-7e41-4a13-886c-e6a3e7413336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec7365-7497-49f4-9235-916663d67ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d89b32-3565-458f-a9c3-496b28ff5358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda8684-8658-4083-af72-2d1957f9e83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
