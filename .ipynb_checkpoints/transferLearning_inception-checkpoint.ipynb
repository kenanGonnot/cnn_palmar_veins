{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86aefc-f6d0-455d-9aef-bc0b5681cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a213c9-c03b-4f1b-a3a0-6e5333383da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48d5e6-43f0-4a79-bdf1-366aac61855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/data_palm_vein/NIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce62474-4908-4ad6-8814-4b41795aa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbd595-42be-40bb-859c-9090d02a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0790bf7-e934-411a-a916-cc9be1801f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9402b5c-c092-4e97-9e4b-8fdc1510d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "def resnet_model_tf(input_shape=(128, 128, 3), nombre_classes=500):\n",
    "    resnet = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    resnet.tbatch_sizenable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.7, \n",
    "                                            min_lr=0.00000000001)\n",
    "    return model, learning_rate_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afcb1f-8954-4f2c-82fc-c45854989d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, learning_rate_reduction = resnet_model_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c38539-3f7c-40d1-a98c-00401c8b6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch = 32\n",
    "\n",
    "print(\"\\n ================= Training : RESNET model ================= \\n\")\n",
    "print(\"             Epochs :  {}   |   Batch size : {} \".format(epochs, batch))\n",
    "print(\"\\n =========================================================== \\n\")\n",
    "trained = model.fit(train_ds, validation_data = val_ds, epochs=epochs, batch_size=batch, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2908ddf-2556-4a4e-8dbf-ec5814608aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model.evaluate(test_ds)\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "print(\"\\n ================= Evaluation : Resnet model ================= \\n\")\n",
    "print(\"  With : \\n\")\n",
    "print(\"Batch size         :  {}     |   Epochs      : {} \".format(batch, epochs))\n",
    "print(\"Nombres de classes :  {}    |   Input shape : {} \\n\".format(len(train_ds.class_names), input_shape))\n",
    "print(\"\\n ============================================================= \\n\")\n",
    "\n",
    "print(\"  Results : \\n\")\n",
    "print(\"Loss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b807be9-798a-4258-bf8f-6ebf608c8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da67ed0-c8fe-46ff-8f85-f7f6c928399e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9fb40-fcaa-4708-973e-59b29f5b34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, xdim=128, ydim=128, nb_of_users = 500):\n",
    "    label_names = []\n",
    "    X = []\n",
    "    y = []\n",
    "    nb_of_users = nb_of_users - 1\n",
    "    count = 0\n",
    "    identity = -1\n",
    "    directories = os.listdir(path)\n",
    "    directories.sort()\n",
    "    for dirname in tqdm_notebook(directories, desc=\"Loading images...\"):\n",
    "        if dirname == \".DS_Store\": continue\n",
    "        label_names.append(dirname)\n",
    "        data_path = os.path.join(path + \"/\" + dirname, '*g')\n",
    "        files = glob.glob(data_path)\n",
    "        if identity >= nb_of_users: break\n",
    "        identity += 1\n",
    "        files.sort()\n",
    "        for f1 in files:\n",
    "            img = cv2.imread(f1, cv2.IMREAD_GRAYSCALE)\n",
    "            #img = cv2.imread(f1)\n",
    "            #img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "            img = cv2.resize(img,(int(xdim*1), int(ydim*1)))\n",
    "            X.append(np.array(img))\n",
    "            y.append(identity)\n",
    "            count += 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"\\n ================= Summary of extraction ================= \\n\")\n",
    "    print(count, ' images lues')\n",
    "    print(\"\\nX.shape = \", X.shape)\n",
    "    print(\"y.shape = \", y.shape)\n",
    "    gc.collect()\n",
    "    return X, y, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e02d4-7f97-4d6b-89c0-bb43ba5f4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, label_names = load_img(path_data, nb_of_users=50, xdim=224, ydim=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47395f4-ce5a-4d77-bd65-149c87a4f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"\\nPREPROCESSING DATA\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"\\nX shape : {}\".format(X.shape))\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"y shape : {}\\n\".format(y.shape))\n",
    "print(\"\\n\\n-----------------------------------------\")\n",
    "print(\"Il y a {} utilisateur(s) dans le dataset prélevé.\".format(y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36a424-1477-4f53-bcac-21b0c975d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\nSplitting data ...\\n\")\n",
    "print(\"\\n=============================== Splitting data =============================== \\n\")\n",
    "print(\"\\nX_train shape : {}    |   y_train shape : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"(X_temp shape : {}    |   y_temp shape : {})\\n\".format(X_temp.shape, y_temp.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77acffe-b5f6-45a7-ae31-4c51c2fafb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(train):\n",
    "    accuracy = train.history['accuracy']\n",
    "    val_accuracy = train.history['val_accuracy']\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_loss(train):\n",
    "    loss = train.history['loss']\n",
    "    val_loss = train.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'b', label='Loss apprentissage')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Loss validation')\n",
    "    plt.title('Scores')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_scores(trained)\n",
    "plot_loss(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5afd6e-4317-4219-8f11-063173d2d011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef5615-d731-47ec-882b-fc2b213cb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(trained)\n",
    "predict_x = model.predict(X_test)\n",
    "y_cnn = np.argmax(predict_x, axis=1)\n",
    "plt.figure(figsize=(15, 25))\n",
    "n_test = X_test.shape[0]\n",
    "i = 1\n",
    "for j in range(len(X_test)):\n",
    "    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i < 10):\n",
    "        plt.subplot(10, 5, i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_test[j])\n",
    "        plt.title('%s / %s' % (Classes[y_cnn[j]], Classes[y_test[j].argmax(axis=-1)]))\n",
    "        i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60301fb-92bc-4e88-a862-69d18ec0a34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
