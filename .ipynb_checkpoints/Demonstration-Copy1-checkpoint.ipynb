{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6c0a00-1531-4718-a8d0-553775ea331e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Palm vein recognition\n",
    "\n",
    "\n",
    "Ici, vous allez trouver tous les étapes nécessaires pour développer un modèle de CNN pour la reconnaissance de veines palmaires. \n",
    "\n",
    "Ce projet a été développé par : Kenan GONNOT, Lorenzo MARQUES et Fayçal MERZOUK.  \n",
    "\n",
    "**L’objectif** est de créer un modèle de veines verification : «Est-ce la bonne personne ? »\n",
    "\n",
    "Vous pouvez retrouver ce code sur [GitHub](https://github.com/kenanGonnot/cnn_palmar_veins). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7bf4dc-1daa-48f7-8c4b-0172ef78164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Imports](#1)\n",
    "- [2 - Load images - Train(70%) Test(15%) Val(15%)](#2)\n",
    "- [4 - Create model CNN](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e16d41b-f67a-4c63-97c2-1ab6cb0c21a4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86aefc-f6d0-455d-9aef-bc0b5681cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a213c9-c03b-4f1b-a3a0-6e5333383da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1869e3c-31b9-47e9-9203-e22a3226e9ca",
   "metadata": {},
   "source": [
    "## Load images - Train(70%) Test(15%) Val(15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48d5e6-43f0-4a79-bdf1-366aac61855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/data_palm_vein/NIR\"\n",
    "weight_path='saved_model/resnet50v2TL_20epochs_32batch.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce62474-4908-4ad6-8814-4b41795aa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbd595-42be-40bb-859c-9090d02a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0790bf7-e934-411a-a916-cc9be1801f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a43360-a240-49dd-83b7-bf65dc610c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1007,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb06f9-ea4b-4a15-85c7-2441affc2e1d",
   "metadata": {},
   "source": [
    "## Creation of the model - ResNet50 with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9402b5c-c092-4e97-9e4b-8fdc1510d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "def resnet_model_tf(input_shape=(128, 128, 3), nombre_classes=500):\n",
    "    resnet = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    resnet.tbatch_sizenable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.7, \n",
    "                                            min_lr=0.00000000001)\n",
    "    return model, learning_rate_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afcb1f-8954-4f2c-82fc-c45854989d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, learning_rate_reduction = resnet_model_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473e033-4814-4f8a-b31a-c9dc66e1512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e4bcc-f81c-4e94-8876-c299689bd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_ds, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd669ca6-90a9-4c09-8ab1-95c045eed67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = list(data)[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b6229-df03-407c-bb2f-5ef72158a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e136bb-ade2-496d-ae66-43e346bab430",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19e57e-8e18-4186-8d1b-97e863aef18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8c039-0a27-49f9-9f7d-1ce89436db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e08b45-0c4e-45ef-8f04-939a33ae5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 24))\n",
    "lass_names = data.class_names\n",
    "for images, labels in data.take(1):\n",
    "    for i in range(32):\n",
    "        ax = plt.subplot(6, 6, i + 1)\n",
    "        y_pred = model.predict(images)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"Real Identity is {}\\nPredict Identity is {}\".format(np.argmax(labels[i]), y_pred[i].argmax()))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45519698-a19c-4916-a8f2-83225ef6ff28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
