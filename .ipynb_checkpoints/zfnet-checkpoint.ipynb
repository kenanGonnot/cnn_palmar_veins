{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "851a9fe7-fd48-4885-b4d0-c77e8f683d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randrange\n",
    "from tqdm import tqdm, tnrange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizer_v2.gradient_descent import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D, Lambda, Dropout, LeakyReLU, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from mlxtend.evaluate import accuracy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD, Nadam\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7949618f-1f6e-40d6-8344-8c79718fa091",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore tensorflow warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3ac1db-7d61-4780-8aa6-a10fb33d9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/data_palm_vein/NIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae3cfe5-c7f6-4856-bd37-70b3a437b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, xdim=128, ydim=128, nb_of_users = 500):\n",
    "    label_names = []\n",
    "    X = []\n",
    "    y = []\n",
    "    nb_of_users = nb_of_users - 1\n",
    "    count = 0\n",
    "    identity = -1\n",
    "    directories = os.listdir(path)\n",
    "    directories.sort()\n",
    "    for dirname in tqdm_notebook(directories, desc=\"Loading images...\"):\n",
    "        if dirname == \".DS_Store\": continue\n",
    "        label_names.append(dirname)\n",
    "        data_path = os.path.join(path + \"/\" + dirname, '*g')\n",
    "        files = glob.glob(data_path)\n",
    "        if identity >= nb_of_users: break\n",
    "        identity += 1\n",
    "        files.sort()\n",
    "        for f1 in files:\n",
    "            img = cv2.imread(f1, cv2.IMREAD_GRAYSCALE)\n",
    "            #img = cv2.imread(f1)\n",
    "            #img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "            img = cv2.resize(img,(int(xdim*1), int(ydim*1)))\n",
    "            #X.append([np.array(img), np.array(img), np.array(img)])\n",
    "            #X.append(np.array(img))\n",
    "            #X.append(np.array(img))\n",
    "            X.append(np.array(img))\n",
    "            #stacked_img = np.stack((img,)*3, axis=-1)\n",
    "            #X.append(stacked_img)\n",
    "            y.append(identity)\n",
    "            count += 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"\\n ================= Summary of extraction ================= \\n\")\n",
    "    print(count, ' images lues')\n",
    "    print(\"\\nX.shape = \", X.shape)\n",
    "    print(\"y.shape = \", y.shape)\n",
    "    gc.collect()\n",
    "    return X, y, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad596e67-c4c3-4820-ae3a-4efb91978f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d15a1cd3cd41bdad73bf2af06d5faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images...:   0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================= Summary of extraction ================= \n",
      "\n",
      "600  images lues\n",
      "\n",
      "X.shape =  (600, 224, 224)\n",
      "y.shape =  (600,)\n"
     ]
    }
   ],
   "source": [
    "X, y, label_names = load_img(path_data, nb_of_users=50, xdim=224, ydim=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf451e58-023f-4812-95b7-6121d2429b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREPROCESSING DATA\n",
      "-----------------------------------------\n",
      "\n",
      "X shape : (600, 224, 224, 1)\n",
      "-----------------------------------------\n",
      "y shape : (600, 50)\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------\n",
      "Il y a 50 utilisateur(s) dans le dataset prélevé.\n"
     ]
    }
   ],
   "source": [
    "X = X / 255.\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"\\nPREPROCESSING DATA\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"\\nX shape : {}\".format(X.shape))\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"y shape : {}\\n\".format(y.shape))\n",
    "print(\"\\n\\n-----------------------------------------\")\n",
    "print(\"Il y a {} utilisateur(s) dans le dataset prélevé.\".format(y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1bb2fec-65e2-433b-9116-252b08564aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data ...\n",
      "\n",
      "\n",
      "=============================== Splitting data =============================== \n",
      "\n",
      "\n",
      "X_train shape : (480, 224, 224, 1)    |   y_train shape : (480, 50)\n",
      "------------------------------------------------------------------------------\n",
      "(X_temp shape : (120, 224, 224, 1)    |   y_temp shape  : (120, 50))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\nSplitting data ...\\n\")\n",
    "print(\"\\n=============================== Splitting data =============================== \\n\")\n",
    "print(\"\\nX_train shape : {}    |   y_train shape : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"(X_temp shape : {}    |   y_temp shape  : {})\\n\".format(X_temp.shape, y_temp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa67f84e-033e-4088-bd01-e615a5d741ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zfnet_model(input_shape=(128, 128, 3), nombre_classes=500):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=96, kernel_size=(7, 7), strides=(2, 2), padding=\"valid\", activation=\"LeakyReLU\",\n",
    "                     kernel_initializer=\"uniform\", input_shape=input_shape))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # model.add(Lambda(lambda x: tf.image.per_image_standardization(x)))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding=\"same\",\n",
    "                     activation=\"LeakyReLU\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    # model.add(Lambda(lambda x: tf.image.per_image_standardization(x)))\n",
    "\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                     kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                     kernel_initializer=\"uniform\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding=\"same\",\n",
    "                     activation=\"LeakyReLU\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation=\"LeakyReLU\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=4096, activation=\"LeakyReLU\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=nombre_classes, activation=\"softmax\"))\n",
    "\n",
    "    print(model.summary())\n",
    "    print(\"\\n ================= ZFNET model ================= \\n\")\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.7, \n",
    "                                            min_lr=0.00000000001)\n",
    "#    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "#                                            factor=0.1, patience=1, min_lr=0.00001)\n",
    "\n",
    "\n",
    "    return model, learning_rate_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1a11f7-a383-4d56-bd74-9c69e45a2251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombres de classes : 50   |   Input shape : (224, 224, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Nombre_classes = y.shape[1]\n",
    "input_shape = (X.shape[1], X.shape[2], 1)\n",
    "print(\"\\nNombres de classes : {}   |   Input shape : {}\\n\".format(Nombre_classes, input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0ba2de-b297-4e1c-afec-d947c3ae2b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 109, 109, 96)      4800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 256)       2457856   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                204850    \n",
      "=================================================================\n",
      "Total params: 60,028,914\n",
      "Trainable params: 60,028,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " ================= ZFNET model ================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, learning_rate_reduction = zfnet_model(input_shape=input_shape, nombre_classes=Nombre_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dac73df-34a4-4144-97cb-dde33ed84a05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================= Training : ZFNET model ================= \n",
      "\n",
      "  Epochs :  20   |   Batch size : 32 \n",
      "\n",
      " ========================================================== \n",
      "\n",
      "Epoch 1/20\n",
      "15/15 [==============================] - 9s 529ms/step - loss: 3.8834 - accuracy: 0.0188 - val_loss: 4.0367 - val_accuracy: 0.0083\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 3.8845 - accuracy: 0.0292 - val_loss: 4.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 8s 525ms/step - loss: 3.8911 - accuracy: 0.0271 - val_loss: 4.0352 - val_accuracy: 0.0083\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.8247522277524694e-05.\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 8s 527ms/step - loss: 3.8874 - accuracy: 0.0125 - val_loss: 4.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 8s 536ms/step - loss: 3.8846 - accuracy: 0.0229 - val_loss: 4.0356 - val_accuracy: 0.0083\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.977326610358432e-05.\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 8s 528ms/step - loss: 3.8815 - accuracy: 0.0250 - val_loss: 4.0354 - val_accuracy: 0.0083\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 8s 526ms/step - loss: 3.8876 - accuracy: 0.0312 - val_loss: 4.0353 - val_accuracy: 0.0083\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.3841286272509023e-05.\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 8s 537ms/step - loss: 3.8787 - accuracy: 0.0333 - val_loss: 4.0358 - val_accuracy: 0.0083\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 8s 527ms/step - loss: 3.8803 - accuracy: 0.0333 - val_loss: 4.0366 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.688900263427058e-06.\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 8s 530ms/step - loss: 3.8827 - accuracy: 0.0250 - val_loss: 4.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 8s 524ms/step - loss: 3.8872 - accuracy: 0.0188 - val_loss: 4.0356 - val_accuracy: 0.0083\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.782229866075795e-06.\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 8s 529ms/step - loss: 3.8819 - accuracy: 0.0375 - val_loss: 4.0354 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 8s 528ms/step - loss: 3.8937 - accuracy: 0.0167 - val_loss: 4.0348 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.747560842588427e-06.\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 8s 546ms/step - loss: 3.8815 - accuracy: 0.0396 - val_loss: 4.0347 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 8s 531ms/step - loss: 3.8804 - accuracy: 0.0375 - val_loss: 4.0349 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.3232926853088427e-06.\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 8s 527ms/step - loss: 3.8819 - accuracy: 0.0271 - val_loss: 4.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 3.8833 - accuracy: 0.0333 - val_loss: 4.0349 - val_accuracy: 0.0083\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.3263049115485044e-06.\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 3.8865 - accuracy: 0.0208 - val_loss: 4.0348 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 8s 524ms/step - loss: 3.8804 - accuracy: 0.0292 - val_loss: 4.0349 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.6284134062516385e-06.\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 3.8850 - accuracy: 0.0375 - val_loss: 4.0349 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "print(\"\\n ================= Training : ZFNET model ================= \\n\")\n",
    "print(\"  Epochs :  {}   |   Batch size : {} \".format(epochs, batch_size))\n",
    "print(\"\\n ========================================================== \\n\")\n",
    "\n",
    "trained_model = model.fit(X_train, y_train, validation_data=(X_temp, y_temp), epochs=epochs, callbacks=learning_rate_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b70f1e-9d55-467b-9e59-adc67f06abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0349 - accuracy: 0.0000e+00\n",
      "\n",
      " ================= Evaluation : ZFNET model ================= \n",
      "\n",
      "  With : \n",
      "\n",
      "Batch size         :  32     |   Epochs      : 20 \n",
      "Nombres de classes :  50     |   Input shape : (224, 224, 1) \n",
      "\n",
      "\n",
      " ============================================================= \n",
      "\n",
      "  Results : \n",
      "\n",
      "Loss  : 403.49%\n",
      "Score : 0.00%\n"
     ]
    }
   ],
   "source": [
    "val = model.evaluate(X_temp, y_temp)\n",
    "\n",
    "print(\"\\n ================= Evaluation : ZFNET model ================= \\n\")\n",
    "print(\"  With : \\n\")\n",
    "print(\"Batch size         :  {}     |   Epochs      : {} \".format(batch_size, epochs))\n",
    "print(\"Nombres de classes :  {}     |   Input shape : {} \\n\".format(Nombre_classes, input_shape))\n",
    "print(\"\\n ============================================================= \\n\")\n",
    "\n",
    "print(\"  Results : \\n\")\n",
    "print(\"Loss  : %.2f%%\" % (val[0] * 100))\n",
    "print(\"Score : %.2f%%\" % (val[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b6bb3-05ed-4236-9263-1770d5e61245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
